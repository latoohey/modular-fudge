{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For debugging as needed\n",
        "# import os\n",
        "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "metadata": {
        "id": "p292zU-3PPc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LApwcli2o1V3",
        "outputId": "90997318-70c8-4a9f-e649-529ddd0c8010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate bitsandbytes huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBf3Ztbko7Qe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# We need argparse.Namespace to reconstruct the 'args' object\n",
        "# that was saved inside the checkpoint\n",
        "from argparse import Namespace"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Args:\n",
        "* `grid` - tests a list of prompts - each at different lambdas\n",
        "* `targeted` - tests a specific `prompt` (supplied as arg) - each at different lambdas\n",
        "* `prompted` - starts a user interface loop"
      ],
      "metadata": {
        "id": "UI8-IDD7xjj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ❗️ Point this to the folder in your Google Drive containing the model\n",
        "DRIVE_PATH = \"/content/drive/My Drive/modular-fudge/trained_models/\"\n",
        "# MODEL_NAME = \"lstm_e_20251109_222627\" # wihtout .pth.tar extention\n",
        "MODEL_NAME = \"lstm_h_20251109_052253\"\n",
        "\n",
        "# (You will need to accept the license on Hugging Face first for Llama!)\n",
        "LLM_MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "# LLM_MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "testing_args = {\n",
        "    \"type\": \"prompted\",\n",
        "    \"prompt\": \"Write a brief summary of the concept of 'philosophy'\",\n",
        "}\n",
        "\n",
        "SEED = 24601\n",
        "\n",
        "TOKENIZER_NAME = 'meta-llama/Llama-3.2-3B-Instruct'\n",
        "PAD_TOKEN = '[PAD]'\n",
        "\n",
        "HIDDEN_DIM = 300\n",
        "\n",
        "MAX_NEW_TOKENS = 300\n",
        "TOP_K = 300\n",
        "\n",
        "# Calculated config\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "model_checkpoint = f'{MODEL_NAME}.pth.tar'\n",
        "CKPT_PATH = os.path.join(DRIVE_PATH, model_checkpoint)"
      ],
      "metadata": {
        "id": "Acyw2dRLw_GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8e4ec1-54af-4bec-9202-a9298c967131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXawwm7fo922",
        "outputId": "72eb4ead-9541-4a46-fee8-e7ed131fef4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGZwvmwho-d-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# We need argparse.Namespace to reconstruct the 'args' object\n",
        "# that was saved inside the checkpoint\n",
        "from argparse import Namespace\n",
        "\n",
        "# --- From util.py ---\n",
        "def num_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# --- From models ---\n",
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, args, vocab_size, pad_token_id):\n",
        "        \"\"\"\n",
        "        Initializes the LSTM model.\n",
        "\n",
        "        Args:\n",
        "            args: The full ArgumentParser namespace. Reads\n",
        "                  `args.lstm_hidden_dim` and `args.lstm_num_layers`.\n",
        "            vocab_size: The total vocabulary size for the embedding layer.\n",
        "            pad_token_id: The ID of the padding token.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=args.lstm_hidden_dim,\n",
        "            padding_idx=pad_token_id\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.LSTM(\n",
        "            args.lstm_hidden_dim,\n",
        "            args.lstm_hidden_dim,\n",
        "            num_layers=args.lstm_num_layers,\n",
        "            bidirectional=False,\n",
        "            dropout=0.5,\n",
        "            batch_first=True # Makes the permute/transpose logic simpler\n",
        "        )\n",
        "        self.out_linear = nn.Linear(args.lstm_hidden_dim, 1)\n",
        "\n",
        "    def forward(self, inputs, lengths):\n",
        "        \"\"\"\n",
        "        Internal forward pass for the LSTM.\n",
        "        Requires `lengths` for sequence packing.\n",
        "        \"\"\"\n",
        "        # (batch_size, seq_len, hidden_dim)\n",
        "        embedded_inputs = self.embed(inputs)\n",
        "\n",
        "        # Pack sequence for efficient RNN processing\n",
        "        packed_inputs = pack_padded_sequence(\n",
        "            embedded_inputs,\n",
        "            lengths.cpu(), # Must be on CPU\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        # rnn_output is (packed_batch, hidden_dim)\n",
        "        rnn_output, _ = self.rnn(packed_inputs)\n",
        "\n",
        "        # Unpack: (batch_size, seq_len, hidden_dim)\n",
        "        rnn_output, _ = pad_packed_sequence(\n",
        "            rnn_output,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # (batch_size, seq_len)\n",
        "        return self.out_linear(rnn_output).squeeze(2)\n",
        "\n",
        "    def get_final_scores(self, batch):\n",
        "        \"\"\"\n",
        "        Returns the scores for the last token of each sequence in the batch.\n",
        "        Used by the guided generation to condition on the last generated token.\n",
        "        \"\"\"\n",
        "        inputs, lengths, _ = batch # _ is targets, not used here\n",
        "        # The forward method returns (batch_size, seq_len)\n",
        "        all_token_scores = self.forward(inputs, lengths)\n",
        "        # Extract the score for the last token of each sequence\n",
        "        # lengths is (batch_size,), all_token_scores is (batch_size, seq_len)\n",
        "        final_scores = all_token_scores[torch.arange(inputs.size(0)), lengths - 1]\n",
        "        return final_scores\n",
        "\n",
        "def get_model(model_args, vocab_size, pad_token_id):\n",
        "    \"\"\"\n",
        "    Factory function to create a model based on model_args.\n",
        "    Assumes model_args contains 'model_type' and relevant model-specific parameters.\n",
        "    \"\"\"\n",
        "    if model_args.model_type == 'lstm':\n",
        "        return LSTMClassifier(model_args, vocab_size, pad_token_id)\n",
        "    # Add other model types here if necessary\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {model_args.model_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "najPrIy3qPld"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxdjt-q1pC8u"
      },
      "outputs": [],
      "source": [
        "def load_classifier(ckpt_path, device, args):\n",
        "    \"\"\"Loads a trained classifier from a checkpoint using the model factory.\"\"\"\n",
        "    print(f\"Loading classifier from {ckpt_path}...\")\n",
        "    checkpoint = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Load args *from the checkpoint* to know what model to build\n",
        "    model_args = checkpoint['args']\n",
        "\n",
        "    # This assumes your main_train.py saved 'tokenizer_name' in its args\n",
        "    if not hasattr(model_args, 'tokenizer_name'):\n",
        "        tokenizer_name = TOKENIZER_NAME\n",
        "    else:\n",
        "        tokenizer_name = model_args.tokenizer_name # Use tokenizer name from checkpoint args\n",
        "\n",
        "    classifier_tokenizer = AutoTokenizer.from_pretrained(\n",
        "        tokenizer_name,\n",
        "        token=args.hf_token # Use token from CLI args\n",
        "    )\n",
        "    # Llama models often don't have a pad_token by default. Assign eos_token as pad_token\n",
        "    # to ensure vocabulary size consistency with training and provide a pad_token_id.\n",
        "    if classifier_tokenizer.pad_token is None:\n",
        "        classifier_tokenizer.pad_token = classifier_tokenizer.eos_token\n",
        "\n",
        "    # Get vocab size and pad_token_id for the model\n",
        "    vocab_size = len(classifier_tokenizer)\n",
        "    pad_token_id = classifier_tokenizer.pad_token_id # Get pad_token_id here\n",
        "\n",
        "    # --- Use the factory to build the correct model ---\n",
        "    model = get_model(model_args, vocab_size, pad_token_id)\n",
        "\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Classifier loaded (Type: {model_args.model_type}, Epochs: {checkpoint['epoch']}).\")\n",
        "    return model, classifier_tokenizer\n",
        "\n",
        "def generate_guided(\n",
        "    llm,\n",
        "    llm_tokenizer,\n",
        "    classifier,\n",
        "    classifier_tokenizer,\n",
        "    prompt,\n",
        "    max_len,\n",
        "    condition_lambda,\n",
        "    top_k\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs FUDGE-style guided generation for a single prompt.\n",
        "    This function is now model-agnostic.\n",
        "    \"\"\"\n",
        "    device = llm.device\n",
        "\n",
        "    # --- Create the Llama 3.1 Chat Prompt ---\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    # This applies the template and adds the \"assistant\" prompt\n",
        "    input_ids = llm_tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # We store the original prompt's length to slice it off later\n",
        "    prompt_length = input_ids.shape[1]\n",
        "    generated_ids = input_ids\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            # --- A: Get Base LLM Logits ---\n",
        "            llm_outputs = llm(generated_ids)\n",
        "            # Get logits (which are float16) and cast them to float32\n",
        "            next_token_logits = llm_outputs.logits[:, -1, :].float()\n",
        "\n",
        "            # --- B: Get Top-K Candidates ---\n",
        "            top_logits, top_indices = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "            # --- C: Run Classifier on Candidates ---\n",
        "\n",
        "            # 1. Create k candidate prefixes\n",
        "            candidate_prefixes = torch.cat(\n",
        "                [generated_ids.expand(top_k, -1), top_indices.squeeze(0).unsqueeze(-1)],\n",
        "                dim=-1\n",
        "            )\n",
        "\n",
        "            # 2. Get the lengths.\n",
        "            # Since all candidate_prefixes are the same length (no padding),\n",
        "            # we can create the lengths tensor directly.\n",
        "            current_seq_len = candidate_prefixes.shape[1]\n",
        "            lengths = torch.LongTensor([current_seq_len] * top_k).to(device)\n",
        "\n",
        "            # 3. Create the batch directly from the token IDs\n",
        "            #    We are skipping the decode/re-encode step!\n",
        "            batch = [\n",
        "                candidate_prefixes,  # Use the LLM's token IDs directly\n",
        "                lengths,\n",
        "                None\n",
        "            ]\n",
        "\n",
        "            # 4. Get classifier scores\n",
        "            #    The 'get_final_scores' adapter works as-is.\n",
        "            last_token_logits = classifier.get_final_scores(batch)\n",
        "\n",
        "            # --- D: Combine and Select ---\n",
        "\n",
        "            # Get LLM log probs: log(P(x))\n",
        "            llm_log_probs = F.log_softmax(top_logits, dim=-1)\n",
        "\n",
        "            # We need log(P(a|x)), which for a binary classifier\n",
        "            # logit is log(sigmoid(logit)).\n",
        "            # This gives the log-probability of the *positive class* (style=1).\n",
        "            classifier_log_probs = F.logsigmoid(last_token_logits)\n",
        "\n",
        "            # FUDGE: log(P(x|a)) = log(P(x)) + lambda * log(P(a|x))\n",
        "            # Shape: (1, top_k) + (top_k,) -> (1, top_k)\n",
        "            combined_log_probs = llm_log_probs + (condition_lambda * classifier_log_probs)\n",
        "\n",
        "            best_token_index = torch.argmax(combined_log_probs)\n",
        "            next_token_id = top_indices[0, best_token_index].unsqueeze(0)\n",
        "\n",
        "            # --- E: Append and Yield/Repeat ---\n",
        "            generated_ids = torch.cat([generated_ids, next_token_id.unsqueeze(0)], dim=-1)\n",
        "\n",
        "            # --- THIS IS THE NEW LOGIC ---\n",
        "            # 1. Decode the single new token\n",
        "            new_text = llm_tokenizer.decode(next_token_id.squeeze(0), skip_special_tokens=True)\n",
        "\n",
        "            # 2. \"Yield\" it back to the caller\n",
        "            yield new_text\n",
        "            # --- END OF NEW LOGIC ---\n",
        "\n",
        "            if next_token_id.item() == llm_tokenizer.eos_token_id:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "14d7631f768448d9b47d7feaa1b11424",
            "54d95aa70bd946e58e0fa6184f20da65",
            "0353cfb4d2ee4757bf3b0dedb5ac9b99",
            "483fac19fcd14582a9e16b949ba06a1c",
            "e9cf0eb99c6c403e83ba2314dfb41729",
            "06046aeecd4c49f8ba3cb132a01bbddd",
            "dab6c714d17c45d9aa72c9471e6e1d1a",
            "0e01b1ab93704b5f9211bdd27ee90e4d",
            "a5844ba44807490fab6b8a0482dba085",
            "e742d40a32c24d2aba485deda81b6f36",
            "939b1f6aa7c840d0a60da1ecf4f6267f",
            "a892638d1058431a943f49efc50a3ebb",
            "770c4cfc03114a12b12e5396cbdbded5",
            "2893142f4f9e4916a68f070fa1b62da2",
            "a17406adcdcb49f38a21156e009e24ad",
            "e9dc72c99e1242299e131da7d20f767c",
            "a4b5e064be1c473695127f86905310df",
            "298b00ba6bbf4044a13f51a503c817df",
            "074383c6aa7140beabf32914b48dbc5f",
            "5c954722a92346c99b32438f593869ae",
            "d029a78fcbea4538ad71cf72eaf85f78",
            "5123f5ed1d7549c9b16ad2a03b18468e",
            "ffbadb8f84094602b905742eb49e5e79",
            "a253c8f783d7403ba36e291f101af359",
            "c76da19373fc47d7babfd8a792316487",
            "4cf606218edd4fb5b5fb3afb70488fed",
            "4d447811c590483e846466449516bc74",
            "227d5f9ca42844f5a99713e0aaf219f0",
            "63515a4c82584142b23b70f438b3405f",
            "d4db9e1b708f4aa1ba6ef92d4b77c4c7",
            "42409132c5364b5aad34172149ea9fd5",
            "20378347ee474aee94d63e6d6b73d4ef",
            "f20405b92701404ebf171a9792c2a8c3"
          ]
        },
        "id": "Vp2L6eBDpEyG",
        "outputId": "bbd5938e-1090-4bde-8778-abcaa763d205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading classifier from /content/drive/My Drive/modular-fudge/trained_models/lstm_h_20251109_052253.pth.tar...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d7631f768448d9b47d7feaa1b11424"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a892638d1058431a943f49efc50a3ebb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffbadb8f84094602b905742eb49e5e79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier loaded (Type: lstm, Epochs: 8).\n",
            "--- Classifier loaded! ---\n"
          ]
        }
      ],
      "source": [
        "# Set seeds for reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Create a Namespace object for runtime arguments, especially for hf_token\n",
        "from argparse import Namespace\n",
        "runtime_args = Namespace(hf_token=hf_token) # hf_token is a kernel variable\n",
        "\n",
        "# 1. Load our trained LSTM classifier\n",
        "classifier, classifier_tokenizer = load_classifier(CKPT_PATH, DEVICE, runtime_args)\n",
        "\n",
        "print(\"--- Classifier loaded! ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model= LLM_MODEL_NAME\n",
        " # 2. Load the base LLM\n",
        "print(f\"Loading base LLM: {llm_model}...\")\n",
        "llm = AutoModelForCausalLM.from_pretrained(\n",
        "    llm_model,\n",
        "    dtype=torch.float16\n",
        ").to(DEVICE)\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    TOKENIZER_NAME\n",
        ")\n",
        "if llm_tokenizer.pad_token is None:\n",
        "    llm_tokenizer.add_special_tokens({'pad_token': PAD_TOKEN})\n",
        "\n",
        "print(\"--- LLM loaded! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "5f38da8329bd4e40a61c15b33f609ca7",
            "46d0f2789dd44dbc88b94d12699a3bf1",
            "213a21f2514941318c2001949cd15f02",
            "f4a352c9da7f44219883f689a85477df",
            "6335c8da7d2e4ba8b9d03c289ddce16e",
            "da95b0f6129b42358b38f93c16dd4f54",
            "bf56a8fbdb4442e68f583e84a5854599",
            "0e01481499f54482b5476f5989dcce92",
            "5382c01e6d65482eb66d56ef60dae9fa",
            "1722d8fd0097443594fce2779d5640a8",
            "7c2183700b8746d29c034e618a10e0bb"
          ]
        },
        "id": "mf6bGcf_6Fli",
        "outputId": "138ad43b-768a-4eb9-b031-1e973447576b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base LLM: meta-llama/Llama-3.2-3B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f38da8329bd4e40a61c15b33f609ca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LLM loaded! ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHNgxaqRpIPe"
      },
      "outputs": [],
      "source": [
        "def prompted_testing():\n",
        "  run = True\n",
        "  while run:\n",
        "      try:\n",
        "          prompt = input(\"Enter a prompt (or 'q' to quit): \")\n",
        "          if prompt.lower() == 'q':\n",
        "              break\n",
        "          condition_lambda_str = input(\"Enter a lambda value: \")\n",
        "          print(f\"--- Generating with lambda={int(condition_lambda_str)} ---\")\n",
        "\n",
        "          output_generator = generate_guided(\n",
        "              llm,\n",
        "              llm_tokenizer,\n",
        "              classifier,\n",
        "              classifier_tokenizer,\n",
        "              prompt,\n",
        "              MAX_NEW_TOKENS,\n",
        "              int(condition_lambda_str),\n",
        "              TOP_K\n",
        "          )\n",
        "          for new_token in output_generator:\n",
        "            print(new_token, end=\"\", flush=True)\n",
        "          print(\"\\n---\") # Add a newline at the end\n",
        "\n",
        "      except KeyboardInterrupt:\n",
        "          print(\"\\nExiting.\")\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fySBN-rhx-rU"
      },
      "outputs": [],
      "source": [
        "def targeted_testing(prompt=\"Write a mystery story.\"):\n",
        "  lambdas = [0.0, 5.0, 10.0, 20.0]\n",
        "  for lambda_val in lambdas:\n",
        "    output_generator = generate_guided(\n",
        "              llm,\n",
        "              llm_tokenizer,\n",
        "              classifier,\n",
        "              classifier_tokenizer,\n",
        "              prompt,\n",
        "              MAX_NEW_TOKENS,\n",
        "              lambda_val,\n",
        "              TOP_K\n",
        "          )\n",
        "    # 2. Exhaust the generator into a single string\n",
        "    full_output = \"\".join(list(output_generator))\n",
        "    output = full_output.strip()\n",
        "    print(f\"\\nGUIDED OUTPUT (lambda={lambda_val}):\\n\", output)\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Who was Albert Einstein?\",\n",
        "    \"Explain what artificial intelligence is.\",\n",
        "    \"How does a neural network work?\",\n",
        "    \"What are some recent advancements in renewable energy?\",\n",
        "    \"I just got promoted at work!\",\n",
        "    \"I’m feeling really down today.\",\n",
        "    \"The weather is nice today.\",\n",
        "    \"Write a short story about a robot who dreams of becoming human.\",\n",
        "    \"Generate a poem about love.\",\n",
        "    \"Give me three ideas for a birthday surprise.\",\n",
        "    \"Generate a story about space exploration.\",\n",
        "    \"Write a short story about a time traveler who meets a famous historical figure.\",\n",
        "    \"What's a good way to spend a sunny day in the park?\",\n",
        "    \"Are people fundamentally good?\",\n",
        "    \"What is the key to happiness?\",\n",
        "    \"Who is the greatest military leader in history?\",\n",
        "    \"What was life like in London at the start of the twentieth century?\",\n",
        "    \"How do you learn to play an instrument?\",\n",
        "    \"Compare and contrast impressionism and realism.\",\n",
        "    \"What causes sepsis?\",\n",
        "    \"Write a mystery story\"\n",
        "]"
      ],
      "metadata": {
        "id": "piYKBhq7nXgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import tqdm\n",
        "import time\n",
        "import os\n",
        "\n",
        "def grid_testing():\n",
        "\n",
        "  log_file = f\"/content/drive/My Drive/modular-fudge/tests/{MODEL_NAME}_tests.csv\"\n",
        "\n",
        "  headers = ['top_k', 'lambda', 'prompt', 'elapsed_time', 'output']\n",
        "\n",
        "  if not os.path.exists(log_file):\n",
        "      with open(log_file, 'w', newline='') as csvfile:\n",
        "          csv_writer = csv.writer(csvfile)\n",
        "          csv_writer.writerow(headers)\n",
        "      print(f\"CSV file '{log_file}' created with headers.\")\n",
        "  else:\n",
        "      print(f\"CSV file '{log_file}' already exists.\")\n",
        "\n",
        "  lambdas = [0.0, 5.0, 10.0, 15.0, 20.0]\n",
        "  for prompt in prompts:\n",
        "    print(f\"Testing prompt: {prompt}\")\n",
        "    for lambda_val in lambdas:\n",
        "      print(f\"@ lambda: {lambda_val}\")\n",
        "      np.random.seed(SEED)\n",
        "      torch.manual_seed(SEED)\n",
        "      if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "      start_time = time.time()\n",
        "      output_generator = generate_guided(\n",
        "            llm,\n",
        "            llm_tokenizer,\n",
        "            classifier,\n",
        "            classifier_tokenizer,\n",
        "            prompt,\n",
        "            MAX_NEW_TOKENS,\n",
        "            lambda_val,\n",
        "            TOP_K\n",
        "        )\n",
        "      # 2. Exhaust the generator into a single string\n",
        "      full_output = \"\".join(list(output_generator))\n",
        "      output = full_output.strip()\n",
        "      end_time = time.time()\n",
        "      elapsed_time = end_time - start_time\n",
        "\n",
        "      new_row_data = [TOP_K, lambda_val, prompt, elapsed_time, output]\n",
        "      with open(log_file, 'a', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow(new_row_data)"
      ],
      "metadata": {
        "id": "1uD04G3Q4uDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(testing_args):\n",
        "  if (testing_args[\"type\"]==\"prompted\"):\n",
        "    prompted_testing()\n",
        "  elif (testing_args[\"type\"]==\"targeted\"):\n",
        "    targeted_testing(testing_args[\"prompt\"])\n",
        "  elif (testing_args[\"type\"]==\"grid\"):\n",
        "    grid_testing()"
      ],
      "metadata": {
        "id": "-5jrIREnx7lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css_output_wrap():\n",
        "    display(HTML('''\n",
        "    <style>\n",
        "    div.output_text pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "    div.output_subarea pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "    </style>\n",
        "    '''))\n",
        "\n",
        "set_css_output_wrap()\n",
        "\n",
        "test(testing_args)"
      ],
      "metadata": {
        "id": "d5SoXDFX0c8V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14d7631f768448d9b47d7feaa1b11424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54d95aa70bd946e58e0fa6184f20da65",
              "IPY_MODEL_0353cfb4d2ee4757bf3b0dedb5ac9b99",
              "IPY_MODEL_483fac19fcd14582a9e16b949ba06a1c"
            ],
            "layout": "IPY_MODEL_e9cf0eb99c6c403e83ba2314dfb41729"
          }
        },
        "54d95aa70bd946e58e0fa6184f20da65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06046aeecd4c49f8ba3cb132a01bbddd",
            "placeholder": "​",
            "style": "IPY_MODEL_dab6c714d17c45d9aa72c9471e6e1d1a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0353cfb4d2ee4757bf3b0dedb5ac9b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e01b1ab93704b5f9211bdd27ee90e4d",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5844ba44807490fab6b8a0482dba085",
            "value": 54528
          }
        },
        "483fac19fcd14582a9e16b949ba06a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e742d40a32c24d2aba485deda81b6f36",
            "placeholder": "​",
            "style": "IPY_MODEL_939b1f6aa7c840d0a60da1ecf4f6267f",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 3.13MB/s]"
          }
        },
        "e9cf0eb99c6c403e83ba2314dfb41729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06046aeecd4c49f8ba3cb132a01bbddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab6c714d17c45d9aa72c9471e6e1d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e01b1ab93704b5f9211bdd27ee90e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5844ba44807490fab6b8a0482dba085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e742d40a32c24d2aba485deda81b6f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939b1f6aa7c840d0a60da1ecf4f6267f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a892638d1058431a943f49efc50a3ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_770c4cfc03114a12b12e5396cbdbded5",
              "IPY_MODEL_2893142f4f9e4916a68f070fa1b62da2",
              "IPY_MODEL_a17406adcdcb49f38a21156e009e24ad"
            ],
            "layout": "IPY_MODEL_e9dc72c99e1242299e131da7d20f767c"
          }
        },
        "770c4cfc03114a12b12e5396cbdbded5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b5e064be1c473695127f86905310df",
            "placeholder": "​",
            "style": "IPY_MODEL_298b00ba6bbf4044a13f51a503c817df",
            "value": "tokenizer.json: 100%"
          }
        },
        "2893142f4f9e4916a68f070fa1b62da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074383c6aa7140beabf32914b48dbc5f",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c954722a92346c99b32438f593869ae",
            "value": 9085657
          }
        },
        "a17406adcdcb49f38a21156e009e24ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d029a78fcbea4538ad71cf72eaf85f78",
            "placeholder": "​",
            "style": "IPY_MODEL_5123f5ed1d7549c9b16ad2a03b18468e",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 14.0MB/s]"
          }
        },
        "e9dc72c99e1242299e131da7d20f767c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b5e064be1c473695127f86905310df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298b00ba6bbf4044a13f51a503c817df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "074383c6aa7140beabf32914b48dbc5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c954722a92346c99b32438f593869ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d029a78fcbea4538ad71cf72eaf85f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5123f5ed1d7549c9b16ad2a03b18468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffbadb8f84094602b905742eb49e5e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a253c8f783d7403ba36e291f101af359",
              "IPY_MODEL_c76da19373fc47d7babfd8a792316487",
              "IPY_MODEL_4cf606218edd4fb5b5fb3afb70488fed"
            ],
            "layout": "IPY_MODEL_4d447811c590483e846466449516bc74"
          }
        },
        "a253c8f783d7403ba36e291f101af359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_227d5f9ca42844f5a99713e0aaf219f0",
            "placeholder": "​",
            "style": "IPY_MODEL_63515a4c82584142b23b70f438b3405f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c76da19373fc47d7babfd8a792316487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4db9e1b708f4aa1ba6ef92d4b77c4c7",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42409132c5364b5aad34172149ea9fd5",
            "value": 296
          }
        },
        "4cf606218edd4fb5b5fb3afb70488fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20378347ee474aee94d63e6d6b73d4ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f20405b92701404ebf171a9792c2a8c3",
            "value": " 296/296 [00:00&lt;00:00, 39.3kB/s]"
          }
        },
        "4d447811c590483e846466449516bc74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227d5f9ca42844f5a99713e0aaf219f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63515a4c82584142b23b70f438b3405f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4db9e1b708f4aa1ba6ef92d4b77c4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42409132c5364b5aad34172149ea9fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20378347ee474aee94d63e6d6b73d4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20405b92701404ebf171a9792c2a8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f38da8329bd4e40a61c15b33f609ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46d0f2789dd44dbc88b94d12699a3bf1",
              "IPY_MODEL_213a21f2514941318c2001949cd15f02",
              "IPY_MODEL_f4a352c9da7f44219883f689a85477df"
            ],
            "layout": "IPY_MODEL_6335c8da7d2e4ba8b9d03c289ddce16e"
          }
        },
        "46d0f2789dd44dbc88b94d12699a3bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da95b0f6129b42358b38f93c16dd4f54",
            "placeholder": "​",
            "style": "IPY_MODEL_bf56a8fbdb4442e68f583e84a5854599",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "213a21f2514941318c2001949cd15f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e01481499f54482b5476f5989dcce92",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5382c01e6d65482eb66d56ef60dae9fa",
            "value": 2
          }
        },
        "f4a352c9da7f44219883f689a85477df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1722d8fd0097443594fce2779d5640a8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c2183700b8746d29c034e618a10e0bb",
            "value": " 2/2 [00:02&lt;00:00,  1.09it/s]"
          }
        },
        "6335c8da7d2e4ba8b9d03c289ddce16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da95b0f6129b42358b38f93c16dd4f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf56a8fbdb4442e68f583e84a5854599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e01481499f54482b5476f5989dcce92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5382c01e6d65482eb66d56ef60dae9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1722d8fd0097443594fce2779d5640a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c2183700b8746d29c034e618a10e0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}